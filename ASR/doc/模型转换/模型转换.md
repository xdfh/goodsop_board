
wsl --shutdown

WSL Ubuntu 终端中，严格按顺序执行以下所有命令。
第一步：准备工作区和 Python 环境

```
# --- 1. 创建并进入我们的工作目录 (这仍在C盘，但只会存放少量文件) ---
cd ~
mkdir -p asr_final_conversion
cd asr_final_conversion

# --- 2. 路径配置 (直接指向您的D盘) ---
# 我们把 D 盘的路径定义为变量，方便后续使用
TOOLKIT_PATH="/mnt/d/file/RK3562/rknn-toolkit2/rknn-toolkit2-2.3.0"
MODEL_PATH="/mnt/d/file/asr/FireRedASR/model.pth.tar"

# --- 3. 设置代理 (如果新开终端需要重新运行) ---
export http_proxy=http://192.168.1.31:7897
export https_proxy=http://192.168.1.31:7897

# --- 4. 创建并激活 Python 虚拟环境 (它会留在C盘，以保证性能) ---
python3.11 -m venv venv
source venv/bin/activate

# --- 5. 配置 pip 代理并升级 ---
mkdir -p ~/.config/pip
tee ~/.config/pip/pip.conf <<EOF
[global]
proxy = http://192.168.1.31:7897
EOF
pip install --upgrade pip
```

第二步：安装所有依赖

```
# --- 1. 安装核心库 ---
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install onnx onnxruntime pyyaml

# --- 2. 安装 wenet (克隆到C盘，保证性能) ---
git clone https://github.com/wenet-e2e/wenet.git
pip install -e ./wenet

# --- 3. 安装 RKNN Toolkit 2 (直接从D盘的路径安装) ---
pip install "${TOOLKIT_PATH}/rknn-toolkit2/packages/x86_64/rknn_toolkit2-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
```


第三步：执行模型转换
您无需修改任何 Python 脚本，只需确保 config.yaml, dict.txt 和我们之前创建的 Python 脚本（export_to_onnx.py, prepare_dataset.py, convert_to_rknn.py）都位于当前的 ~/asr_final_conversion 目录中，并且 model.pth.tar 的加载路径在脚本中是正确的。
为保险起见，这是为您准备的、路径绝对正确的 export_to_onnx.py：
export_to_onnx.py

```
import torch
import yaml
from wenet.utils.init_model import init_model

# 直接从D盘读取模型
MODEL_PATH="/mnt/d/file/asr/FireRedASR/model.pth.tar"

def export_to_onnx():
    print("--- 开始导出 ONNX 模型 ---")
    with open('config.yaml', 'r') as f:
        configs = yaml.load(f, Loader=yaml.FullLoader)
    
    model = init_model(configs)
    
    print(f"--> 正在加载模型权重: {MODEL_PATH}")
    checkpoint = torch.load(MODEL_PATH, map_location='cpu')
    model.load_state_dict(checkpoint, strict=False)
    model.eval()
    print("--> 模型权重加载完成。")

    # ...后续代码与之前版本相同...
    # (创建虚拟输入, torch.onnx.export 等)
    input_dim = configs['input_dim']
    batch_size = 1
    sequence_length = 100
    dummy_input = torch.randn(batch_size, sequence_length, input_dim, requires_grad=True)
    dummy_input_lengths = torch.LongTensor([sequence_length])
    output_onnx_file = 'firered_asr.onnx'
    print(f"--> 正在导出到: {output_onnx_file}")
    torch.onnx.export(
        model, (dummy_input, dummy_input_lengths), output_onnx_file,
        export_params=True, opset_version=12, do_constant_folding=True,
        input_names=['input', 'input_lengths'], output_names=['output'],
        dynamic_axes={'input': {1: 'sequence_length'}, 'output': {1: 'sequence_length'}}
    )
    print("--- ONNX 模型导出成功！ ---")


if __name__ == '__main__':
    export_to_onnx()
```

